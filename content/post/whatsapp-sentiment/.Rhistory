knitr::opts_chunk$set(echo = FALSE, cache = TRUE)
options(scipen = 999)
library(tidyverse)
library(lubridate)
library(ggplot2)
detach('package:dplyr')
library(dplyr)
library(tidytext)
library(sentimentr)
library(viridis)
library(magrittr)
library(wesanderson)
library(kableExtra)
library(knitr)
process_text <- function(filename){
df <-
read.csv(filename, header = TRUE, stringsAsFactors = FALSE) %>%
select(datetime, sender, text) %>%
mutate(datetime = dmy_hms(datetime),
date = date(datetime),
day = lubridate::wday(date, label = TRUE, abbr = FALSE)) %>%
group_by(date,sender) %>%
mutate(all_text = paste0(text, collapse = ".")) %>%
select(date, sender, all_text) %>%
unique() %>%
mutate(all_text = str_replace_all(all_text, 'image omitted', ' ')) %>%
select(all_text, everything()) %>%
mutate(all_text = textclean::replace_emoji(all_text),
all_text = str_replace_all(all_text, "\\<[a-z][a-z]\\>", ' '),
all_text = str_replace_all(all_text, "\\<[a-z][0-9]\\>", ' '),
all_text = str_replace_all(all_text, "\\<[0-9][a-z]\\>", ' '),
all_text = str_replace_all(all_text, "\\<[0-9][0-9]\\>", ' '),
dialogue_split = get_sentences(all_text)) %$%
sentiment_by(dialogue_split, list(sender,date),
polarity_dt = lexicon::hash_sentiment_senticnet) %>%
mutate(norm_sentiment = ave_sentiment/word_count)
return(df)
}
chats <-list.files('data')
d <- process_text(paste('data/',chats[1], sep = '')) %>%
mutate(sender = ifelse(sender == 'Didige','Friend 1','Me'))
n <- process_text(paste('data/',chats[2], sep = '')) %>%
mutate(sender = ifelse(sender == 'Nikhil','Friend 2','Me'))
p <- process_text(paste('data/',chats[3], sep = '')) %>%
mutate(sender = ifelse(sender == 'Pranathi','Friend 3','Me'))
r <- process_text(paste('data/',chats[4], sep = '')) %>%
mutate(sender = ifelse(sender == 'Riddhima','Friend 4','Me'))
friends <- bind_rows(d,n,p,r) %>%
mutate(binary_sender = case_when(sender == 'Me' ~ 'Sent',
TRUE ~ 'Received'))
transcripts <- bind_rows(
read_csv(paste('data/',chats[1], sep = '')),
read_csv(paste('data/',chats[2], sep = '')),
read_csv(paste('data/',chats[3], sep = '')),
read_csv(paste('data/',chats[4], sep = ''))) %>%
select(datetime, sender, text) %>%
mutate(datetime = dmy_hms(datetime),
date = date(datetime),
day = lubridate::wday(date, label = TRUE, abbr = FALSE)) %>%
group_by(date,sender) %>%
mutate(all_text = paste0(text, collapse = " ")) %>%
select(date, sender, all_text)
p
p %>% filter(date == date('2018-10-01'))
p %>% filter(date == date('2018-10-02'))
p %>% filter(date == date('2018-10-03'))
p %>% filter(date == date('2018-10-20'))
p %>% filter(date == date('2018-10-2`'))
p %>% filter(date == date('2018-10-21'))
p %>%
filter(date == date('2018-10-21') & filter(sender == 'Me'))
p %>%
filter(date == date('2018-10-21') %>% filter(sender == 'Me')
p %>%
filter(date == date('2018-10-21')) %>% filter(sender == 'Me')
p %>%
filter(date == date('2018-10-21')) %>% filter(sender == 'Me') %>%
pull(ave_sentiment)
p %>%
filter(date == date('2018-10-21')) %>%
filter(sender == 'Me') %>%
pull(ave_sentiment)[1]
(p %>%
filter(date == date('2018-10-21')) %>%
filter(sender == 'Me') %>%
pull(ave_sentiment))[1]
p %>%
filter(date == date('2018-10-21')) %>%
filter(sender == 'Me') %>%
pull(ave_sentiment)
example <- p %>%
filter(date == date('2018-10-21')) %>%
filter(sender == 'Me') %>%
pull(ave_sentiment)
knitr::opts_chunk$set(echo = FALSE, cache = TRUE)
options(scipen = 999)
library(tidyverse)
library(lubridate)
library(ggplot2)
detach('package:dplyr')
library(dplyr)
library(tidytext)
library(sentimentr)
library(viridis)
library(magrittr)
library(wesanderson)
library(kableExtra)
library(knitr)
process_text <- function(filename){
df <-
read.csv(filename, header = TRUE, stringsAsFactors = FALSE) %>%
select(datetime, sender, text) %>%
mutate(datetime = dmy_hms(datetime),
date = date(datetime),
day = lubridate::wday(date, label = TRUE, abbr = FALSE)) %>%
group_by(date,sender) %>%
mutate(all_text = paste0(text, collapse = ".")) %>%
select(date, sender, all_text) %>%
unique() %>%
mutate(all_text = str_replace_all(all_text, 'image omitted', ' ')) %>%
select(all_text, everything()) %>%
mutate(all_text = textclean::replace_emoji(all_text),
all_text = str_replace_all(all_text, "\\<[a-z][a-z]\\>", ' '),
all_text = str_replace_all(all_text, "\\<[a-z][0-9]\\>", ' '),
all_text = str_replace_all(all_text, "\\<[0-9][a-z]\\>", ' '),
all_text = str_replace_all(all_text, "\\<[0-9][0-9]\\>", ' '),
dialogue_split = get_sentences(all_text)) %$%
sentiment_by(dialogue_split, list(sender,date),
polarity_dt = lexicon::hash_sentiment_senticnet) %>%
mutate(norm_sentiment = ave_sentiment/word_count)
return(df)
}
chats <-list.files('data')
d <- process_text(paste('data/',chats[1], sep = '')) %>%
mutate(sender = ifelse(sender == 'Didige','Friend 1','Me'))
n <- process_text(paste('data/',chats[2], sep = '')) %>%
mutate(sender = ifelse(sender == 'Nikhil','Friend 2','Me'))
p <- process_text(paste('data/',chats[3], sep = '')) %>%
mutate(sender = ifelse(sender == 'Pranathi','Friend 3','Me'))
r <- process_text(paste('data/',chats[4], sep = '')) %>%
mutate(sender = ifelse(sender == 'Riddhima','Friend 4','Me'))
friends <- bind_rows(d,n,p,r) %>%
mutate(binary_sender = case_when(sender == 'Me' ~ 'Sent',
TRUE ~ 'Received'))
transcripts <- bind_rows(
read_csv(paste('data/',chats[1], sep = '')),
read_csv(paste('data/',chats[2], sep = '')),
read_csv(paste('data/',chats[3], sep = '')),
read_csv(paste('data/',chats[4], sep = ''))) %>%
select(datetime, sender, text) %>%
mutate(datetime = dmy_hms(datetime),
date = date(datetime),
day = lubridate::wday(date, label = TRUE, abbr = FALSE)) %>%
group_by(date,sender) %>%
mutate(all_text = paste0(text, collapse = " ")) %>%
select(date, sender, all_text)
example <- p %>%
filter(date == date('2018-10-21')) %>%
filter(sender == 'Me') %>%
pull(ave_sentiment)
blogdown::serve_site()
